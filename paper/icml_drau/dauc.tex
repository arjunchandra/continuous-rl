%! TEX root = icml_drau.tex
\begin{algorithmic}
	\STATE \textbf{Inputs:}
	\STATE $\theta_1$ and $\theta_2$, parameters of
	$V_{\theta_1}$ and $\bar{A}_{\theta_2}$.
	\STATE $\theta_1'$ parameter of target $V_{\theta_1'}$.
	\STATE $\pi_{\text{exp}}$ exploration policy.
	\STATE \textbf{opt}$_1$, \textbf{opt}$_2$, $\eta_1$ and $\eta_2$ optimizers and learning rates.
	\STATE $\mathcal{D}$, buffer of transitions $(s, a, r, d, s')$.
	\STATE $\deltat$ and $\gamma$, time discretization and discount factor.
	\STATE $\tau$, target network update factor.
	\STATE \textbf{nb\_epochs} number of epochs.
	\STATE \textbf{nb\_steps}, number of steps per epoch.
	\STATE
	\STATE Observe initial state $s^0$
	\STATE $t \gets 0$
	\FOR {$e=0, \textbf{nb\_epochs}$}
	\FOR {$k=1, \textbf{nb\_steps}$}
	\STATE Sample $a_t$ according to $\pi_{\text{exp}}$.
	\STATE Perform $a_t$ and observe $(r_{t+1}, d_{t+1}, s_{t+1})$.
	\STATE Store $(s_t, a_t, r_{t+1}, d_{t+1}, s_{t+1})$ in $\mathcal{D}$.
	\STATE Update $\pi_{\text{exp}}$ with $(a_t, s_{t+1})$.
	\STATE $t \gets t + 1$
	\ENDFOR
	\FOR {$k=0, \text{nb\_learn}$}
	\STATE \text{Sample a batch of $N$ random transitions from $\mathcal{D}$}
	\STATE $Q^i \gets V_{\theta_1}(s^i) + \deltat\hspace{-.17em}\left(
	\bar{A}_{\theta_2}(s^i, a^i) - \max\limits_{a'}\bar{A}_{\theta_2}(s^i, a')\right)$
	\STATE $\tilde{Q^i} \gets r^i + (1 - d^i) \gamma^{\deltat} V_{\theta_1}(s'^i)$
	\STATE $\Delta \theta_1 \gets \sum\limits_{i=1}^N \partial_{\theta_1} V_{\theta_1}(s^i) (Q^i - \tilde{Q^i})$
	\STATE $\Delta \theta_2 \gets \sum\limits_{i=1}^N \partial_{\theta_2} A_{\theta_2}(s^i, a^i) (Q^i - \tilde{Q^i})$
	\STATE Update $\theta_1$ using \textbf{opt}$_1$ with $\Delta \theta_1$ and learning rate $\eta_1$.
	\STATE Update $\theta_2$ using \textbf{opt}$_2$ with $\Delta \theta_2$ and learning rate $\eta_2$.
	\STATE $\theta_1' \gets \tau \theta_1' + (1 - \tau) \theta_1$
	\ENDFOR
	\ENDFOR
\end{algorithmic}
