@inproceedings{adv_upd,
  title={Reinforcement learning in continuous time: Advantage updating},
  author={Baird, Leemon C},
  booktitle={Neural Networks, 1994. IEEE World Congress on Computational Intelligence., 1994 IEEE International Conference on},
  volume={4},
  pages={2448--2453},
  year={1994},
  organization={IEEE}
}
@incollection{adv_learn,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}
@article{dueling_nets,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}
@article{drl_matter,
	author    = {Peter Henderson and
	      Riashat Islam and
	      Philip Bachman and
	      Joelle Pineau and
	      Doina Precup and
	      David Meger},
	title     = {Deep Reinforcement Learning that Matters},
	journal   = {CoRR},
	volume    = {abs/1709.06560},
	year      = {2017},
	url       = {http://arxiv.org/abs/1709.06560},
	archivePrefix = {arXiv},
	eprint    = {1709.06560},
	timestamp = {Mon, 13 Aug 2018 16:45:58 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-06560},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{drl_matter_bis,
	author    = {Amy Zhang and
	      Yuxin Wu and
	      Joelle Pineau},
	title     = {Natural Environment Benchmarks for Reinforcement Learning},
	journal   = {CoRR},
	volume    = {abs/1811.06032},
	year      = {2018},
	url       = {http://arxiv.org/abs/1811.06032},
	archivePrefix = {arXiv},
	eprint    = {1811.06032},
	timestamp = {Sat, 24 Nov 2018 17:52:00 +0100},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06032},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{dqn,
	title={Human-level control through deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	journal={Nature},
	volume={518},
	number={7540},
	pages={529},
	year={2015},
	publisher={Nature Publishing Group}
}
@article{ddpg,
	author    = {Timothy P. Lillicrap and
	      Jonathan J. Hunt and
	      Alexander Pritzel and
	      Nicolas Heess and
	      Tom Erez and
	      Yuval Tassa and
	      David Silver and
	      Daan Wierstra},
	title     = {Continuous control with deep reinforcement learning},
	journal   = {CoRR},
	volume    = {abs/1509.02971},
	year      = {2015},
	url       = {http://arxiv.org/abs/1509.02971},
	archivePrefix = {arXiv},
	eprint    = {1509.02971},
	timestamp = {Mon, 13 Aug 2018 16:46:11 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/LillicrapHPHETS15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hand_control,
	author    = {OpenAI},
	title     = {Learning Dexterous In-Hand Manipulation},
	journal   = {CoRR},
	volume    = {abs/1808.00177},
	year      = {2018},
	url       = {http://arxiv.org/abs/1808.00177},
	archivePrefix = {arXiv},
	eprint    = {1808.00177},
	timestamp = {Sun, 02 Sep 2018 15:01:56 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1808-00177},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{alphazero,
	title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
	author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
	journal={arXiv preprint arXiv:1712.01815},
	year={2017}
}

@misc{openai_five,
	author = {OpenAI},
	title = {OpenAI Five},
	howpublished = {\url{https://blog.openai.com/openai-five/}},
	year = {2018}
}

@article{cont_rl,
	title={Reinforcement learning in continuous time and space},
	author={Doya, Kenji},
	journal={Neural computation},
	volume={12},
	number={1},
	pages={219--245},
	year={2000},
	publisher={MIT Press}
}

@book{sutton,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{orn-uhl,
  title={On the theory of the Brownian motion},
  author={Uhlenbeck, George E and Ornstein, Leonard S},
  journal={Physical review},
  volume={36},
  number={5},
  pages={823},
  year={1930},
  publisher={APS}
}
@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{MunosBourgines98,
  title={Reinforcement learning for continuous stochastic control problems},
  author={Munos, R{\'e}mi and Bourgine, Paul},
  booktitle={Advances in neural information processing systems},
  pages={1029--1035},
  year={1998}
}

@article{rmsprop,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}
